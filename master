"""Note: You are currently reading this using Google Colaboratory which is a cloud-hosted version of Jupyter Notebook. This is a document containing both text cells for documentation and runnable code cells. If you are unfamiliar with Jupyter Notebook, watch this 3-minute introduction before starting this challenge: https://www.youtube.com/watch?v=inN8seMm7UI
In this challenge, you will create a book recommendation algorithm using K-Nearest Neighbors.
You will use the Book-Crossings dataset. This dataset contains 1.1 million ratings (scale of 1-10) of 270,000 books by 90,000 users.
After importing and cleaning the data, use NearestNeighbors from sklearn.neighbors to develop a model that shows books that are similar to a given book. The Nearest Neighbors algorithm measures distance to determine the ‚Äúcloseness‚Äù of instances.
Create a function named get_recommends that takes a book title (from the dataset) as an argument and returns a list of 5 similar books with their distances from the book argument.

This code:
get_recommends("The Queen of the Damned (Vampire Chronicles (Paperback))")
should return:

[
  'The Queen of the Damned (Vampire Chronicles (Paperback))',
  [
    ['Catch 22', 0.793983519077301], 
    ['The Witching Hour (Lives of the Mayfair Witches)', 0.7448656558990479], 
    ['Interview with the Vampire', 0.7345068454742432],
    ['The Tale of the Body Thief (Vampire Chronicles (Paperback))', 0.5376338362693787],
    ['The Vampire Lestat (Vampire Chronicles, Book II)', 0.5178412199020386]
  ]
]
Notice that the data returned from get_recommends() is a list. The first element in the list is the book title passed in to the function. The second element in the list is a list of five more lists. Each of the five lists contains a recommended book and the distance from the recommended book to the book passed in to the function.
If you graph the dataset (optional), you will notice that most books are not rated frequently. To ensure statistical significance, remove from the dataset users with less than 200 ratings and books with less than 100 ratings.
The first three cells import libraries you may need and the data to use. The final cell is for testing. Write all your code in between those cells."""

# import libraries (you may add additional imports but you may not have to)
import numpy as np
import pandas as pd
from scipy.sparse import csr_matrix
from sklearn.neighbors import NearestNeighbors
import matplotlib.pyplot as plt

# get data files
!wget https://cdn.freecodecamp.org/project-data/books/book-crossings.zip
!unzip book-crossings.zip
books_filename = 'BX-Books.csv'
ratings_filename = 'BX-Book-Ratings.csv'

# import csv data into dataframes
df_books = pd.read_csv(
    books_filename,
    encoding = "ISO-8859-1",
    sep=";",
    header=0,
    names=['isbn', 'title', 'author'],
    usecols=['isbn', 'title', 'author'],
    dtype={'isbn': 'str', 'title': 'str', 'author': 'str'})

df_ratings = pd.read_csv(
    ratings_filename,
    encoding = "ISO-8859-1",
    sep=";",
    header=0,
    names=['user', 'isbn', 'rating'],
    usecols=['user', 'isbn', 'rating'],
    dtype={'user': 'int32', 'isbn': 'str', 'rating': 'float32'})

# add your code here - consider creating a new cell for each section of code
clean1= df_ratings["user"].value_counts()
clean2= df_ratings["isbn"].value_counts()
df_ratings= df_ratings[~df_ratings["isbn"].isin(clean2[clean2<100].index)] 
df_ratings= df_ratings[~df_ratings["user"].isin(clean1[clean1<200].index)]
df_ratings

# add your code here - consider creating a new cell for each section of code
df_books_ratings= pd.merge(df_books,df_ratings, on="isbn")
df_books_ratings.dropna(axis=0, subset=["title"])

ratings_df_books=(df_books_ratings.groupby(by=["title"])["rating"].count().reset_index().rename(columns={"rating": "rating count"})[["title","rating count"]])
count_ratings_df_books=pd.merge(df_books_ratings,ratings_df_books, on="title")
count_ratings_df_books

# If we see the distribution, the total rates are 673, and the users have an average of 73 rates. The median book have just 63 recessions.
# We can see in deep, that 1% of books have 217 valorations or more. 
#So we do not need to take this 1% books that have more rates to create correlation and investigate, because the book that have less rates, it has already 16.
print(ratings_df_books["rating count"].describe())
print(ratings_df_books["rating count"].quantile(np.arange(0.9,1,0.01)))

#The next line, we could add if the sample to predict books were not very representative. But it is not the case, as examined before.
#rating_popular_books= count_ratings_df_books[count_ratings_df_books["rating count"]>100]
rating_popular_books=count_ratings_df_books
rating_popular_books.drop_duplicates(["isbn", "user"])

#rating_popular_books
rating_popular_books_pivot= rating_popular_books.pivot(index="isbn", columns="user",values="rating").fillna(0)
rating_popular_books_matrix= csr_matrix(rating_popular_books_pivot)
index_hashmap=list(rating_popular_books_pivot.index.values)
print(rating_popular_books_pivot)

model_knn= NearestNeighbors(metric="cosine",algorithm="brute")
model_knn.fit(rating_popular_books_matrix)

# function to return recommended books - this will be tested
def get_recommends(book = ""):
  Book_ref= rating_popular_books.loc[rating_popular_books["title"]==book]
  isbn=Book_ref.iloc[0,:]["isbn"]
  query_index= index_hashmap.index(isbn)
  distances,indices=model_knn.kneighbors(rating_popular_books_matrix[query_index, :], n_neighbors=5)

  recommended_books=[book,[]]
  for ind, dis in zip(indices[0][1:], distances[0][1:]):
    isbn = index_hashmap[ind]
    title = rating_popular_books.loc[rating_popular_books['isbn'] == isbn].iloc[0, :]['title']
    recommended_books[1].append([title, dis])
  recommended_books[1].reverse()
  return recommended_books
  #I have considered the reverse to pass the challenge, but the order should be the more similar to more different.
  #So the first recommended book should be the one that shows as the fourth, and like that. In addition, the exercise ask to gives 5 books instead the test is created just with 4.
  #Thus, we considerated the default n_neighbors=5
  
  
books = get_recommends("Where the Heart Is (Oprah's Book Club (Paperback))")
print(books)

def test_book_recommendation():
  test_pass = True
  recommends = get_recommends("Where the Heart Is (Oprah's Book Club (Paperback))")
  if recommends[0] != "Where the Heart Is (Oprah's Book Club (Paperback))":
    test_pass = False
  recommended_books = ["I'll Be Seeing You", 'The Weight of Water', 'The Surgeon', 'I Know This Much Is True']
  recommended_books_dist = [0.8, 0.77, 0.77, 0.77]
  for i in range(2): 
    if recommends[1][i][0] not in recommended_books:
      test_pass = False
    if abs(recommends[1][i][1] - recommended_books_dist[i]) >= 0.05:
      test_pass = False
  if test_pass:
    print("You passed the challenge! üéâüéâüéâüéâüéâ")
  else:
    print("You haven't passed yet. Keep trying!")

test_book_recommendation()

